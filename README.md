# MAGE-AI Project
 
## Pr√©sentation
Ce projet vise √† d√©velopper une solution de maintenance pr√©dictive bas√©e sur l'apprentissage automatique, l'int√©gration de flux de donn√©es (Kafka, InfluxDB) et la visualisation via Streamlit et Grafana.
 
## Structure du projet
```
dataset_machine.csv
input_inference_*.csv
train_dataset.csv
models/
    lstm_maintenance_model.h5
    lstm_maintenance_model_metadata.pkl
    lstm_maintenance_model_scaler.pkl
    model_version.txt
src/
    deployment/
        inference.py
        train.py
        test.py
    streaming/
        extract_data_influxdb.py
        kafka_to_influxdb.py
        model_to_influx_db.py
        producer.py
        streaming_processor.py
    visualisation/
        setup_grafana.py
streamlit_dashboard.py
Dockerfile.streamlit
requirements.txt
docker-compose.yml
README.md
```
 
## üì¶ Docker Compose
 
Le fichier `docker-compose.yml` lance les services suivants :
 
- `zookeeper` et `broker` Kafka
- `influxdb` avec bucket `machines-data`
- `grafana` avec datasource pr√©configur√©e
- `control-center` pour monitoring Kafka
 
```bash
docker compose up -d
 
## Installation
1. Cloner le d√©p√¥t‚ÄØ:
   ```powershell
git clone <url-du-repo>
```
2. Installer les d√©pendances Python‚ÄØ:
   ```powershell
pip install -r requirements.txt
```
3. (Optionnel) D√©marrer les services via Docker‚ÄØ:
   ```powershell
docker-compose up
```
 
## Utilisation
- **Entra√Ænement du mod√®le**‚ÄØ: `src/deployment/train.py`
- **Inf√©rence**‚ÄØ: `src/deployment/inference.py` et fichiers `input_inference_*.csv`
- **Dashboard Streamlit**‚ÄØ: `streamlit_dashboard.py`
- **Streaming et int√©gration**‚ÄØ: scripts dans `src/streaming/`
- **Visualisation Grafana**‚ÄØ: `src/visualisation/setup_grafana.py`
 
## Mod√®les et donn√©es
- Mod√®le LSTM sauvegard√© dans `models/`
- Jeux de donn√©es‚ÄØ: `train_dataset.csv`, `dataset_machine.csv`, `input_inference_*.csv`
 